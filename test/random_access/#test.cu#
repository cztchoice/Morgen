/*
 *   Random Access Test
 *
 *   Copyright (C) 2013 by
 *   Cheng Yichao        onesuperclark@gmail.com
 *
 *   This program is free software; you can redistribute it and/or modify
 *   it under the terms of the GNU General Public License as published by
 *   the Free Software Foundation; either version 2 of the License, or
 *   (at your option) any later version.
 *
 *   This program is distributed in the hope that it will be useful,
 *   but WITHOUT ANY WARRANTY; without even the implied warranty of
 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *   GNU General Public License for more details.
 */


#include <argvparser/argvparser.h>
#include <cstdlib>
#include <stdio.h>
#include <iostream>
#include <morgen/utils/handle_error.cuh>
#include <morgen/utils/print_value.cuh>
#include <morgen/utils/array.cuh>
#include <morgen/utils/timer.cuh>

using namespace Morgen;
using namespace CommandLineProcessing;
using namespace std;


/********************************************************************************
 * Globals
 ********************************************************************************/

int      g_num_strides_log      = 0;     
int      g_num_elements         = 1024;
int      g_num_iterations       = 1;
bool     g_local                = false;


/**********************************************************************************
 * Init parameters
 **********************************************************************************/

void Init(int argc, char** argv) {

    ArgvParser cmd;

    // help option
    cmd.setHelpOption("help", "h", "help menu");

    // options with value
    cmd.defineOption("stride", "stride of writing atomically",
                     ArgvParser::OptionRequiresValue); 
    cmd.defineOption("elements", "how many numbers to be performed on",
                     ArgvParser::OptionRequiresValue);
    cmd.defineOption("iterations", "how many iterations to be performed",
                     ArgvParser::OptionRequiresValue);
    
    // without value
    cmd.defineOption("local", "use local kernel(or global kernel)");

    ArgvParser::ParserResults result = cmd.parse(argc, argv);


    if (result != ArgvParser::NoParserError) {
        cout << cmd.parseErrorDescription(result)
             << "  (type -h for help) \n";
        exit(1);
    }

    
    if (cmd.foundOption("stride")) {
        const char* s = cmd.optionValue("stride").c_str();
        g_num_strides_log = atoi(s);
    }


    if (cmd.foundOption("elements")) {
        const char* s = cmd.optionValue("elements").c_str();
        g_num_elements = atoi(s);
    }

    if (cmd.foundOption("iterations")) {
        const char* s = cmd.optionValue("blocks").c_str();
        g_num_iterations = atoi(s);
    }

    
    if (cmd.foundOption("local")) {
        g_local = true;
    }

}


/************************************************************************************
 * Kernels
 ************************************************************************************/

__global__ void GlobalAtomicKernel(
    int *d_in,
    int *d_out,
    int stride,
    int tiles_per_block,
    int extra_tiles) 
{

    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    int temp;
    
    /*
     * extra_tiles == 3 means only 3 blocks of threads need to
     * process the extra tiles. So increase the tiles
     */
    if (blockIdx.x < extra_tiles) {
        tiles_per_block++;
    } 


    for (int i = 0; i < tiles_per_block; i++) {
        temp = d_in[tid];
        
        d_out[temp] = 6;
        tid += gridDim.x * blockDim.x;
    }
}


__global__ void LocalAtomicKernel(
    int *d_in,
    int *d_out,
    int stride,
    int tiles_per_block,
    int extra_tiles) 
{
 
    
    // each block has a critical variable
    __shared__ int s_counter[8196];

    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    int temp;
    
    /*
     * extra_tiles == 3 means only 3 blocks of threads need to
     * process the extra tiles. So increase the tiles
     */
    if (blockIdx.x < extra_tiles) {
        tiles_per_block++;
    } 


    for (int i = 0; i < tiles_per_block; i++) {
        temp = d_in[tid];              

        atomicAdd( & s_counter[threadIdx.x % stride], 1);
                
        d_out[tid] = temp;

        tid += gridDim.x * blockDim.x;
    }


}



/*************************************************************************************
 * Main
 *************************************************************************************/

int main(int argc, char** argv) 
{

    Init(argc, argv);


    cout << "stride(log):\t elements:\t local:\t iterations:\t \n"    
         << g_num_strides_log   << "\t"
         << g_num_elements      << "\t"
         << g_local             << "\t"
         << g_num_iterations    << "\n";
         

    const int COUNTER_SIZE = 20000;

    // host alloc
    int *in = new int[g_num_elements];
    int *out = new int[g_num_elements];
    int *counter = new int[COUNTER_SIZE]();  // all 0
    
    // in is a random array
    util::RandomizeArray<int>(in, g_num_elements, g_num_elements);
   

    // device alloc
    int *d_in = NULL;
    int *d_out = NULL;

    Morgen::util::HandleError(cudaMalloc((void**) &d_in, sizeof(int) * g_num_elements),
                              "cudaMalloc d_in fail",
                              __FILE__,
                              __LINE__);
    Morgen::util::HandleError(cudaMalloc((void**) &d_out, sizeof(int) * g_num_elements),
                              "cudaMalloc d_out fail",
                              __FILE__,
                              __LINE__);


    if (NULL == d_in || NULL == d_out) {
        printf("cudamalloc fail!\n");
        exit(1);
    }

    // copy data_in to device
    Morgen::util::HandleError(cudaMemcpy(d_in, in, sizeof(int) * g_num_elements,
                                         cudaMemcpyHostToDevice),
                              "cudaMemcpy in to device fail",
                              __FILE__,
                              __LINE__);

    /*
     * NOTE:
     * We will enlist as much blocks as possible to process tiles
     * but no more than MAX_NUM_BLOCKS.
     * The extra tiles will be assigned iteratively in the kernel,
     * which means tiles_per_block > 1
     * In some cases, tiles cannot be divided by num_blocks,
     * so we need handle this situation by extra_tiles
     */

    const int THREADS_PER_BLOCK = 256;
    const int MAX_NUM_BLOCKS = 1024 * 16;    

    int tiles = (g_num_elements + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;

    int num_blocks = (tiles > MAX_NUM_BLOCKS) ?
            MAX_NUM_BLOCKS :
            tiles;
    
    int tiles_per_block = tiles / num_blocks;
    int extra_tiles = tiles - (tiles_per_block * num_blocks);
    int strides = 1 << g_num_strides_log;



    cout << "tiles\t blocks\t  tiles/block\t extra_tiles\t stride:\n"             
         << tiles             << "\t"
         << num_blocks        << "\t"
         << tiles_per_block   << "\t"
         << extra_tiles       << "\t"
         << strides           << "\n";


    // iteration starts
    for (int i = 0; i < g_num_iterations; i++) {
        
        util::GPUTimer timer;

        timer.Start();

        if(g_local) {
            LocalAtomicKernel <<< num_blocks, THREADS_PER_BLOCK >>>(
                d_in,
                d_out,
                strides,
                tiles_per_block,
                extra_tiles);
        } else {
            GlobalAtomicKernel <<< num_blocks, THREADS_PER_BLOCK >>>(
                d_in,
                d_out,
                strides,
                tiles_per_block,
                extra_tiles);
        }        

        timer.Stop();
        
        float millis = timer.ElapsedTime();
        unsigned long long bytes = g_num_elements * sizeof(int) * 2;

        printf("%.3f ms elapesed\n",
               millis);
        printf("%.5f 10^9 bytes/sec   \n",
               float(bytes) / millis / 1000.0 / 1000.0);
    }
    
    // copy data_out to device
    Morgen::util::HandleError(cudaMemcpy(out, d_out, sizeof(int) * g_num_elements,
                                         cudaMemcpyDeviceToHost),
                              "cudaMemcpy out to device fail",
                              __FILE__,
                              __LINE__);

    // validate
    Morgen::util::PrintArray(in, g_num_elements);
    Morgen::util::PrintArray(out, g_num_elements);


    // cleaning
    if (d_in) cudaFree(d_in);
    if (d_out) cudaFree(d_out);    
    delete[] in;
    delete[] out;


    return 0;
}
